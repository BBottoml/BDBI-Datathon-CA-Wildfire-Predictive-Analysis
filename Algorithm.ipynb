{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Wildfire Pipeline Predictive Analysis Program\n",
      "==================================================\n",
      "Gathering data...\n",
      "==================================================\n",
      "Done gathering data...\n",
      "414 potential wildfires identified\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4e262ec20146>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;31m# Create model and determine severity for each potential wildfire\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlatlongs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mlatlong_severity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetermine_severity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;31m# Sort by most severe and display\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-4e262ec20146>\u001b[0m in \u001b[0;36mdetermine_severity\u001b[1;34m(raw_data)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;34m\"\"\"Return a severity score based on model between 0.00-1.00\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# %load pipeline.py\n",
    "from __future__ import print_function\n",
    "from uszipcode import SearchEngine\n",
    "import pandas\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_data_from_lat_long(latlong: tuple):\n",
    "    \"\"\"Return data pertaining to the specified latitude and longitude\"\"\"\n",
    "    search = SearchEngine(simple_zipcode=False)\n",
    "    result = search.by_coordinates(latlong[0], latlong[1], radius=30, returns=1)\n",
    "    if result != []:\n",
    "        return result[0].to_dict()\n",
    "\n",
    "# Data gathering functions \n",
    "\n",
    "def get_population_density(raw_data: dict):\n",
    "    \"\"\"Return the population density for a given region\"\"\"\n",
    "    return raw_data[\"population_density\"]\n",
    "\n",
    "def get_median_home_value(raw_data: dict):\n",
    "    \"\"\"Return the median home value for a given region\"\"\"\n",
    "    return raw_data[\"median_home_value\"]\n",
    "\n",
    "def get_median_household_income(raw_data: dict):\n",
    "    \"\"\"Return the median household income\"\"\"\n",
    "    return raw_data[\"median_household_income\"]\n",
    "\n",
    "def get_number_housing_units(raw_data: dict):\n",
    "    \"\"\"Return the number of housing units in the region\"\"\" \n",
    "    return raw_data[\"housing_units\"]\n",
    "\n",
    "def get_number_occupied_housing_units(raw_data: dict):\n",
    "    \"\"\"Return the number of occupied housing units\"\"\"\n",
    "    return raw_data[\"occupied_housing_units\"]\n",
    "\n",
    "def get_house_age_breakdown(raw_data: dict):\n",
    "    \"\"\"Return a dictionary representing decades in which houses were built\"\"\"\n",
    "    ages_raw = raw_data[\"year_housing_was_built\"][0][\"values\"]\n",
    "    ages = {1930: 0, 1940: 0, 1950: 0, 1960: 0, 1970: 0, 1980: 0, 1990: 0, 2000: 0, 2010: 0} \n",
    "\n",
    "    return transform_dict(ages_raw, ages)\n",
    "\n",
    "def get_degree_breakdown(raw_data: dict):\n",
    "    \"\"\"Return a dictionary representing the number of degree holders\"\"\"\n",
    "    degree_raw = raw_data[\"educational_attainment_for_population_25_and_over\"][0][\"values\"]\n",
    "    degrees = {\"NO_HS\": 0, \"HS\": 0, \"Associates\": 0, \"Bachelors\": 0, \"Masters\": 0, \"Professional\": 0, \"Doctorate\": 0} \n",
    "\n",
    "    return transform_dict(degree_raw, degrees)\n",
    "\n",
    "def get_earnings_breakdown(raw_data: dict):\n",
    "    \"\"\"Return a dictionary representing earnings breakdown\"\"\"\n",
    "    earnings_raw = raw_data[\"source_of_earnings\"][0][\"values\"]\n",
    "    earnings = {\"None\": 0, \"Part_Time\": 0, \"Full_Time\": 0} \n",
    "    \n",
    "    return transform_dict(earnings_raw, earnings)\n",
    "\n",
    "'''\n",
    "def get_household_breakdown(raw_data: dict):\n",
    "    \"\"\"Return a dictionary representing household breakdown\"\"\"\n",
    "    household_raw = raw_data[\"households_with_kids\"][0][\"values\"]\n",
    "'''\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "def get_majority_value(data_dict: dict):\n",
    "    max_val = -1\n",
    "    majority = None\n",
    "    for key, value in data_dict.items():\n",
    "        if value > max_val:\n",
    "            max_val = value \n",
    "            majority = key\n",
    "\n",
    "    return majority\n",
    "\n",
    "def transform_dict(raw_dict, new_dict):\n",
    "    i = 0\n",
    "    for key in new_dict.keys():\n",
    "        new_dict[key] = raw_dict[i][\"y\"]\n",
    "        i += 1\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def determine_severity(raw_data: dict):\n",
    "    \"\"\"Return a severity score based on model between 0.00-1.00\"\"\"\n",
    "    \n",
    "    for i in range(len(raw_data)):\n",
    "        if (i == 0) {\n",
    "            median_household_income =  get_median_home_income(raw_data)\n",
    "            population_density = get_population_density(raw_data)\n",
    "            median_home_value = get_median_home_value(raw_data)\n",
    "            number_housing_units = get_number_housing_units(raw_data)\n",
    "            \n",
    "            df = pandas.DataFrame([[median_household_income,population_density,median_home_value,number_housing_units]])\n",
    "            \n",
    "\n",
    "        df = pandas.concat([df, \n",
    "                            pandas.DataFrame([[median_household_income,\n",
    "                                               population_density,\n",
    "                                               median_home_value,\n",
    "                                               number_housing_units]])], \n",
    "                           ignore_index=True)\n",
    "                                                            \n",
    "    # y = (x - min) / (max - min)  ## standardization: 0 - 1\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #raw_data = (get_data_from_lat_long((33.3062856, -111.8673082))[0]).to_dict()\n",
    "    print(\"=\"*50)\n",
    "    print(\"Wildfire Pipeline Predictive Analysis Program\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Gathering data...\")\n",
    "    \n",
    "\n",
    "    latlongs = {}  # map lat long tuple to raw data dictionary \n",
    "    latlong_severity = {} # map lat long tuple to score determined by model\n",
    "\n",
    "    # GET request to NASA active fire data source\n",
    "    req = requests.get(r'https://firms.modaps.eosdis.nasa.gov/data/active_fire/c6/csv/MODIS_C6_USA_contiguous_and_Hawaii_7d.csv')\n",
    "    if req.status_code != 200:\n",
    "        exit(1)\n",
    "\n",
    "    with open('current_data.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for line in req.iter_lines():\n",
    "            writer.writerow(line.decode('utf-8').split(','))\n",
    "    \n",
    "    data = pandas.read_csv('current_data.csv')\n",
    "    \n",
    "    i = 0\n",
    "    # acquire data for each potential wildfire \n",
    "    data['latlongtuple'] = list(zip(data.latitude, data.longitude, data.confidence))\n",
    "    for item in data['latlongtuple']:\n",
    "        if (item[2] > 95): # determine if confidence is greater than 95 \n",
    "            latlongs[item] = get_data_from_lat_long((item[0], item[1]))\n",
    "            i+=1\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"Done gathering data...\")\n",
    "    print(i, \"potential wildfires identified\")\n",
    "    \n",
    "    \n",
    "    # Create model and determine severity for each potential wildfire \n",
    "    for key,value in latlongs.items():\n",
    "        latlong_severity[key] = determine_severity(value)\n",
    "    \n",
    "    # Sort by most severe and display\n",
    "    '''\n",
    "    #with open('sample_data.json', 'w', encoding='utf-8') as f:\n",
    "    #    json.dump(raw_data, f, ensure_ascii=False, indent=4)\n",
    "    with open(\"sample_data.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    \n",
    "    print(get_earnings_breakdown(data))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3\n",
       "0  0  1  2  3\n",
       "1  1  2  3  4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
