{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13604\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Wildfire Pipeline Predictive Analysis Program\n",
      "==================================================\n",
      "Gathering data...\n",
      "==================================================\n",
      "Done gathering data...\n",
      "842 potential wildfires identified\n",
      "267 wildfires suitable for analysis\n",
      "==================================================\n",
      "                                              raw_data  \\\n",
      "0    {'zipcode_type': 'Standard', 'major_city': 'Mo...   \n",
      "1    {'zipcode_type': 'Standard', 'major_city': 'El...   \n",
      "2    {'zipcode_type': 'Standard', 'major_city': 'Ma...   \n",
      "3    {'zipcode_type': 'Standard', 'major_city': 'Ma...   \n",
      "4    {'zipcode_type': 'Standard', 'major_city': 'Ma...   \n",
      "..                                                 ...   \n",
      "262  {'zipcode_type': 'Standard', 'major_city': 'Po...   \n",
      "263  {'zipcode_type': 'Standard', 'major_city': 'Po...   \n",
      "264  {'zipcode_type': 'Standard', 'major_city': 'He...   \n",
      "265  {'zipcode_type': 'Standard', 'major_city': 'He...   \n",
      "266  {'zipcode_type': 'Standard', 'major_city': 'Vi...   \n",
      "\n",
      "     median_household_income  median_home_value  population_density  \\\n",
      "0                      32078            82500.0                26.0   \n",
      "1                      60714           156500.0                 2.0   \n",
      "2                      19922            66100.0                 1.0   \n",
      "3                      19922            66100.0                 1.0   \n",
      "4                      19922            66100.0                 1.0   \n",
      "..                       ...                ...                 ...   \n",
      "262                    36875            79000.0               627.0   \n",
      "263                    36875            79000.0               627.0   \n",
      "264                    65000            53900.0                 3.0   \n",
      "265                    65000            53900.0                 3.0   \n",
      "266                    30114            52500.0                 2.0   \n",
      "\n",
      "     number_housing_units  normalized_severity_score  \n",
      "0                    26.0                        NaN  \n",
      "1                     2.0                        NaN  \n",
      "2                     1.0                        NaN  \n",
      "3                     1.0                        NaN  \n",
      "4                     1.0                        NaN  \n",
      "..                    ...                        ...  \n",
      "262                 627.0                        NaN  \n",
      "263                 627.0                        NaN  \n",
      "264                   3.0                        NaN  \n",
      "265                   3.0                        NaN  \n",
      "266                   2.0                        NaN  \n",
      "\n",
      "[267 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# %load pipeline.py\n",
    "from __future__ import print_function\n",
    "from uszipcode import SearchEngine\n",
    "import pandas as pd \n",
    "import json\n",
    "import requests\n",
    "import operator\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "def get_data_from_lat_long(latlong: tuple):\n",
    "    \"\"\"Return data pertaining to the specified latitude and longitude\"\"\"\n",
    "    search = SearchEngine(simple_zipcode=False)\n",
    "    result = search.by_coordinates(latlong[0], latlong[1], radius=30, returns=1)\n",
    "    if result != [] and result != None:\n",
    "        return result[0].to_dict()\n",
    "\n",
    "# Data gathering functions \n",
    "\n",
    "def get_population_density(raw_data: dict):\n",
    "    \"\"\"Return the population density for a given region\"\"\"\n",
    "    return raw_data[\"population_density\"]\n",
    "\n",
    "def get_median_home_value(raw_data: dict):\n",
    "    \"\"\"Return the median home value for a given region\"\"\"\n",
    "    return raw_data[\"median_home_value\"]\n",
    "\n",
    "def get_median_household_income(raw_data: dict):\n",
    "    \"\"\"Return the median household income\"\"\"\n",
    "    return raw_data[\"median_household_income\"]\n",
    "\n",
    "def get_number_housing_units(raw_data: dict):\n",
    "    \"\"\"Return the number of housing units in the region\"\"\" \n",
    "    return raw_data[\"housing_units\"]\n",
    "\n",
    "def get_number_occupied_housing_units(raw_data: dict):\n",
    "    \"\"\"Return the number of occupied housing units\"\"\"\n",
    "    return raw_data[\"occupied_housing_units\"]\n",
    "\n",
    "def get_house_age_breakdown(raw_data: dict):\n",
    "    \"\"\"Return a dictionary representing decades in which houses were built\"\"\"\n",
    "    ages_raw = raw_data[\"year_housing_was_built\"][0][\"values\"]\n",
    "    ages = {1930: 0, 1940: 0, 1950: 0, 1960: 0, 1970: 0, 1980: 0, 1990: 0, 2000: 0, 2010: 0} \n",
    "\n",
    "    return transform_dict(ages_raw, ages)\n",
    "\n",
    "def get_degree_breakdown(raw_data: dict):\n",
    "    \"\"\"Return a dictionary representing the number of degree holders\"\"\"\n",
    "    degree_raw = raw_data[\"educational_attainment_for_population_25_and_over\"][0][\"values\"]\n",
    "    degrees = {\"NO_HS\": 0, \"HS\": 0, \"Associates\": 0, \"Bachelors\": 0, \"Masters\": 0, \"Professional\": 0, \"Doctorate\": 0} \n",
    "\n",
    "    return transform_dict(degree_raw, degrees)\n",
    "\n",
    "def get_earnings_breakdown(raw_data: dict):\n",
    "    \"\"\"Return a dictionary representing earnings breakdown\"\"\"\n",
    "    earnings_raw = raw_data[\"source_of_earnings\"][0][\"values\"]\n",
    "    earnings = {\"None\": 0, \"Part_Time\": 0, \"Full_Time\": 0} \n",
    "    \n",
    "    return transform_dict(earnings_raw, earnings)\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "def get_majority_value(data_dict: dict):\n",
    "    max_val = -1\n",
    "    majority = None\n",
    "    for key, value in data_dict.items():\n",
    "        if value > max_val:\n",
    "            max_val = value \n",
    "            majority = key\n",
    "\n",
    "    return majority\n",
    "\n",
    "def transform_dict(raw_dict, new_dict):\n",
    "    i = 0\n",
    "    for key in new_dict.keys():\n",
    "        new_dict[key] = raw_dict[i][\"y\"]\n",
    "        i += 1\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def verify_data(raw_data: dict):\n",
    "    \"\"\"Will verify that raw_data is populated with the necessary fields to perform analysis\"\"\"\n",
    "    try:\n",
    "        get_median_household_income(raw_data)\n",
    "        get_median_home_value(raw_data)\n",
    "        get_population_density(raw_data)\n",
    "        get_number_housing_units(raw_data)\n",
    "    except: \n",
    "        return -1\n",
    "\n",
    "\n",
    "    return 0\n",
    "\n",
    "def construct_dataframe(latlong_list: list):\n",
    "    raw_data_col = [] \n",
    "    income_col = [] \n",
    "    home_val_col = []\n",
    "    pop_density_col = [] \n",
    "    housing_num_unit_col = [] \n",
    "\n",
    "    for latlong in latlong_list:\n",
    "        raw_data_col.append(latlong)\n",
    "        income_col.append(get_median_household_income(latlong))\n",
    "        home_val_col.append(get_median_home_value(latlong))\n",
    "        pop_density_col.append(get_population_density(latlong))\n",
    "        housing_num_unit_col.append(get_population_density(latlong))\n",
    "    \n",
    "    d = {'raw_data': raw_data_col, 'median_household_income': income_col, 'median_home_value': home_val_col, 'population_density': pop_density_col, 'number_housing_units': housing_num_unit_col}\n",
    "    return pd.DataFrame(data=d)\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calculate_vif(features):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Features\"] = features.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]    \n",
    "    return(vif)\n",
    "\n",
    "\n",
    "# temporary name \n",
    "def model_algorithm(data_frame):\n",
    "    \n",
    "    normalized = []\n",
    "    for i in range(len(data_frame)):\n",
    "        \n",
    "        count = (0.25)*data_frame.loc[i, \"median_household_income\"] + (0.25)*data_frame.loc[i, \"median_home_value\"] \n",
    "        + (0.25)*data_frame.loc[i, \"population_density\"] + (0.25)*data_frame.loc[i, \"number_housing_units\"]\n",
    "        \n",
    "        normalized.append(count)\n",
    "       \n",
    "    for i in range(len(normalized)):\n",
    "        normalized[i] = (normalized[i] - statistics.mean(normalized))/statistics.stdev(normalized)\n",
    "    \n",
    "    data_frame[\"normalized_severity_score\"] = normalized\n",
    "    \n",
    "    print(data_frame)\n",
    "    \n",
    "        \n",
    " \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #raw_data = (get_data_from_lat_long((33.3062856, -111.8673082))[0]).to_dict()\n",
    "    print(\"=\"*50)\n",
    "    print(\"Wildfire Pipeline Predictive Analysis Program\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Gathering data...\")\n",
    "    \n",
    "    latlongs = {}  # map lat long tuple to raw data dictionary \n",
    "    '''\n",
    "    0 key: (lat, long, confidence) -> value: {DICT} \n",
    "    1   \n",
    "    2\n",
    "    3\n",
    "    4\n",
    "    5\n",
    "    6\n",
    "    7\n",
    "    ...\n",
    "    N \n",
    "    '''\n",
    "\n",
    "    ''' \n",
    "    Row: (lat, long, confidence): get_median_household_income(raw_data), get_median_home_value(raw_data)\n",
    "    '''\n",
    "\n",
    "    latlong_severity = {} # map lat long tuple to score determined by model\n",
    "\n",
    "    # GET request to NASA active fire data source\n",
    "    req = requests.get(r'https://firms.modaps.eosdis.nasa.gov/data/active_fire/c6/csv/MODIS_C6_USA_contiguous_and_Hawaii_7d.csv')\n",
    "    if req.status_code != 200:\n",
    "        exit(1)\n",
    "\n",
    "    with open('current_data.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for line in req.iter_lines():\n",
    "            writer.writerow(line.decode('utf-8').split(','))\n",
    "    \n",
    "    data = pd.read_csv('current_data.csv')\n",
    "    \n",
    "    # acquire data for each potential wildfire \n",
    "    data['latlongtuple'] = list(zip(data.latitude, data.longitude, data.confidence))\n",
    "    i = 0\n",
    "    for item in data['latlongtuple']:\n",
    "        if (item[2] > 90): # determine if confidence is greater than 95 \n",
    "            latlongs[item] = get_data_from_lat_long((item[0], item[1]))\n",
    "            i+=1\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"Done gathering data...\")\n",
    "    print(i, \"potential wildfires identified\")\n",
    "    \n",
    "    # verify each of the potential wildfires\n",
    "    latlong_list = []\n",
    "    suitable = 0\n",
    "    for key,value in latlongs.items():\n",
    "        if verify_data(value) != -1:\n",
    "            latlong_list.append(value)\n",
    "            suitable+=1\n",
    "    print(suitable, \"wildfires suitable for analysis\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    #print(len(latlong_list))\n",
    "    df = construct_dataframe(latlong_list)\n",
    "    #print(df) \n",
    "\n",
    "    # TODO: Call model_algorithm on the data frame, df \n",
    "    model_algorithm(df)\n",
    "\n",
    "    # Create model and determine severity for each potential wildfire \n",
    "    # Sort by most severe and display\n",
    "    #latlong_severity = sorted(latlong_severity.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print(len(latlong_severity))\n",
    "    '''\n",
    "    #with open('sample_data.json', 'w', encoding='utf-8') as f:\n",
    "    #    json.dump(raw_data, f, ensure_ascii=False, indent=4)\n",
    "    with open(\"sample_data.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    \n",
    "    print(get_earnings_breakdown(data))\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
